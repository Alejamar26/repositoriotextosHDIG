Nordisk musikkpedagogisk forskning. Årbok 18 2017, 9-22Nordic Research in Music Education. Yearbook Vol. 18 2017, 9–22Music, media and technological creativity in the digital ageAnne DanielsenKeynote on the 20th conference of the Nordic Network for Research in Music Education: “Technology and creativity in music education”March 8–10, 2016, Hedmark University College, Hamar, NorwayThe creative use of new digital technology has changed how music is produced, distributed, and consumed, as well as how music sounds. In this keynote, I will begin by examining some creative examples of music production in the digital age, focusing on two new sonic expressions within the field of popular music that have been produced through the unorthodox application of the digital audio workstation, or DAW, and more precisely through manipulations of rhythm and manipulations of the voice, respectively. Then I will discuss new patterns of use and personalized music “consumption,” using playlist creation in streaming services as my point of departure. Lastly, I will address how the two spheres of production and consumption meet in the so-called prosumption practices that have arisen in the digital era in the form of remix, sample and mashup music.
Creating with technologyThe topic of this conference is technology and creativity, which concerns machines and humans and their relationship. Within the field of music, this relationship is often framed as a tension between human performance (creativity) and automated procedures (technology). This is certainly so within the field of rhythm, which is my specialty. Throughout the 1970s and even up to the advent of digital recording in the late 1980s, the field of rhythm was characterized by a discursive and performative dichotomy of human versus machine. On the one hand, there were played styles, such as rock, country, funk, and jazz, that were characterized by “organic” rhythmic feels that derived from both deliberate and unintended variations that musicians add to their performances; on the other hand, there was the music of those artists who produced sequencer-based dance tracks with a futuristic machine aesthetic, typified by Kraftwerk’s albums Man-Machine (1978) and Computer World (1981). These grooves, enabled by analogue sequencers, were often perceived to be non-human and “mechanistic,” largely because of the absence of micro-level flexibility in the temporal placement of their rhythmic events, which were all forced into the grid supplied by the sequencer. This early dichotomy in rhythmic design within 1970s popular music likely informs any potential understanding of the reasons why rhythmic patterns consisting of grid-ordered events are experienced as lacking a human touch (even when they are produced by a human), and why that human touch automatically implies variation, intended or unintended. Rhythmic subdivisions that are too evenly played sound like a machine. Loose timing, on the other hand, is “organic” and evokes human performance, even when the telltale variations have been generated by a computer.Prior to the advent of digital recording, then, there was a de facto difference between played and machine-generated rhythm that was associated with the constraints of the conditions of production within these two spheres. Machine rhythm lacked the intended (and unavoidable non-intended) temporal and sonic variations that were typical of human musicking. Likewise, humans were simply unable to produce the extreme evenness of the machine. Today, however, it is very difficult to distinguish between human and computer-generated performances. The traditional link between machine-based music and stiffness has been disrupted by new opportunities for creating microrhythmic designs in the DAW. In general, digital music technology has introduced unforeseen possibilities for manipulating sound, and, as a consequence, entirely new forms of musical expression have emerged. In what follows, I will focus on some of the trends that have emerged as a consequence of manual or automated techniques for cutting-up sound, warping samples, and manipulating samples using
DAWs. All of these techniques have made an unmistakable mark on popular music styles from the turn of the millennium onward, and they might even be said to repre- sent a new phase in the interaction of human and machine in music history—one characterized by a decisive undermining of the traditional separation between the two in the production of music.Three trends of productionThe first trend comprises electronica-related styles whose rhythmic events align with a metrical grid. Common to the musicianship of the artists representing this trend is a preference for exaggerated tempi and an attraction to the completely straightened-out, “square” feel of quantization. Prominent pioneers of this rhythmic trend include Aphex Twin (the performing pseudonym of Richard D. James), Autechre’s (Sean Booth and Rob Brown), and Squarepusher’s (Tom Jenkinson), all of whom entered the electro- nica scene in the late 1990s and are associated with the label Warp. The fast speed and quantized evenness of many of the tracks on such albums anticipate the related process of musical granulation—that is, of crystallizing “sonic wholes” into grains, so that musical or nonmusical sounds are chopped up into small fragments and reordered to produce a stuttering rhythmic effect. This aesthetic also promotes a tendency to transform sounds with an otherwise clear semantic meaning or reference point—a different musical context, for example, or something else entirely—into “pure” sound (see, for example, Harkins, 2010). Such sounds or clips are also often combined in choppy ways that underline sonic cut-outs rather than disguising them, resulting in a form of “schizophonia”—the kind of euphoric, skittering collage referred to by Fredric Jameson (1984) as the “breakdown of the signifying chain.”The label glitch music—a substyle of electronic dance music associated with the artists mentioned above—hints at the ways in which we perceive these soundscapes, namely as a coherent sonic totality that has been “destroyed,” meaning chopped up and reorganized anew. An important point here, which my colleague R. Brøvig-Hanssen discusses at length, is that this approach to sound relies on the listener being able to imagine a “music within the music”—that is, a fragmented sound presupposes an imagined and spatiotemporally coherent sound (Brøvig-Hanssen, 2013; Brøvig- Hanssen & Danielsen, 2016, chapter 5).
No microtiming is usually present in this practice, in the sense that all of the events (that is, the onsets of the physical signals) are on the grid. The second trend of techn- ologically based creation in the field of rhythm that I will focus on today, on the other hand, pushes the perceptual boundaries of timing discrepancies and irregularities to the limit, and in some cases beyond. An early example was D’Angelo’s legendary Voodoo album (1999), where several songs featured the displacement of tracks in a multi-track recording. In other words, the tracks were moved back and forth on the time axis in the post-production process, resulting in discrepancies between rhythmic layers of up to 100 milliseconds within a given song. This technique is, for example, audible in the songs “Left and Right” (see analysis in Danielsen, 2010) and “Untitled (How Does It Feel)” (see analysis in Bjerke, 2010). The experimental hip-hop and neo- soul coming out of the Soulquarian collective to which D’Angelo belonged, together with artists and bands such as Common, the Roots, and Erykah Badu, could be consi- dered a form of the avant-garde within African American–derived rhythmic genres. An example from more mainstream contemporary R&B using the same techniques is Brandy’s song “What About Us” from her innovative album Full Moon (Atlantic, 2002, produced by Rodney Jerkins) (for analysis, see Carlsen and Witek, 2010).Radical time-warping procedures produce much the same effect, as can be heard on several tracks of Snoop Dogg’s innovative album R&G (Rhythm & Gangsta): The Masterpiece (Geffen, 2004). Here, several producers, among them J. R. Rotem and Josef Leimberg, contributed their take on grooves where the “feel” aspect is almost overdone as a consequence of the manipulation of rhythm in the DAW. The groove of “Can I Get A Flicc Witchu” (produced by Leimberg) consists of a programmed bass riff and a drum kit, along with vocals that are mainly rapped. The texture of the groove is simple and open, but the microrhythmic relationships within it are muddy and complex, thanks to two distinct forms of time warping, or bending the temporal aspects of the groove. First, the length of the beats is gradually shortened, so that beat 2 is shorter than beat 1, beat 3 is shorter than beat 2, and so on. This may be due to the use of tempo automation, a function that was available in the DAW at the time of production of Rhythm & Gangsta. This form of manipulation contributes to a general vagueness regarding the positioning of rhythmic events. Second, the bass pattern is a sample that follows its own peculiar schematic organization and is a main reason for the “seasick” rhythmic feel of the tune. This pattern neither relates to the 4/4 meter nor conforms to a regular periodicity of its own (for a detailed analysis, see Brøvig- Hanssen & Danielsen, 2016, chapter 6).
The third trend that I want to focus on is the creative use of AutoTune, or the so-called Cher effect, which recast autotuning as more than a means of “cheating” the listener. Auto-Tune is the digital age’s answer to the analogue Vocoder, but whereas the vocoder is an analogue synthesis procedure that recreates a synthetic version of the analyzed input signal (for example, a voice), the Auto-Tune plug-in is based on digital signal processing of the numeric representation of the sound wave. Auto-Tune identifies the dominating periodic frequencies, or pitched notes, in the signal using autocorrelation techniques and adjusts them to the nearest periodicity corresponding to one of the notes in a pre-determined scale. That is, it changes the pitch of the signal while keeping its other features intact, which means that the sonic result of using Auto-Tune on a vocal is still a vocal sound, but one deprived of typical human characteristics, such as vibration or sliding transitions between different tones.Its potential for new expressivity has been explored by several hip-hop artists, the first of which was T-Pain, who used pitch-correction software to process his lead vocal on several tracks on the album Rappa Ternt Sanga (Jive) in 2006. A similar use of Auto- Tune is found on Kanye West’s album 808s and Heartbreak (Roc-A-Fella Records, 2008) which, according to the Washington Post, captured “the isolation, paranoia and longing of 21st-century city life” (Richards, 2008). The discourse surrounding Kanye’s release illustrates the win-win situation brought about by digital pitch-correction tools. Correcting and creating are intimately mingled: Auto-Tune assists Kanye in satisfying the responsibilities of a lead vocalist (with perfect intonation) on a professional reco- rding, while at the same time enabling a particular sort of vocal expressiveness that is beyond the reach of transparently mediated human singing. The sad, mechanistic sound of his autotuned voice suited the overall theme of his album, which centers around emotional distance, loneliness, and heartbreak.Auto-Tune’s connotations of the robotic and non-human have also been used to disrupt stereotypical notions of race and/or gender, particularly around the reception of female artists within electro-pop and r&b. The sound is often coupled with imagery depicting exaggerated femininity and hyper-embodiment—that is, a body that comes forward as either perfect in and of itself or otherwise cultivated beyond the human. In her essay on robo-divas in contemporary R&B, Robin James (2008) argues that the robo-diva character subverts stereotypical notions of both femininity and ethnicity by coming across as overtly “constructed” by technology—it thus represents a type of antithesis to naturalized conceptions of gender and/or race.
A last example of the experimental use of Auto-Tune is found on Bon Iver’s track titled “Woods,” from the EP Blood Bank (2009), which is characterized by a peculiar lyrical atmosphere that is closely linked to the use of a clean, opaquely autotuned vocal that soon replicates itself into a digital choir. Measurements of the exact distances between the different phrases in each repetition of the melody indicate that the first repetition was looped and used as the point of departure for all successive rounds (five and a half), because the timing of each repetition is precisely the same. Each repetition, however, adds new voices performing harmonies. In addition, the last repetitions, which are in the higher register, are colored with melismas, which, given the heavy use of digital pitch correction, jump from note to note in a “square” fashion and thus come forward as rather strange (for detailed analysis, see Brøvig-Hanssen & Danielsen, 2016, chapter 7). The cleanliness of the digital choir evokes a feeling of distance and hyperreality, in that there is a total absence of the impure, chaotic, and disturbing aspects of real nature (in this case, the unmediated human voice). Thus, in this context, we might hear the autotuned voice as evoking a sense of nature as perfection—that is to say, we hear nature as culture, or nature as a means of getting in touch with one’s authentic self.The creative use of digital technology as demonstrated by the Auto-Tune and micror- hythmic examples described above has brought about a new situation in which played and machine-generated music are deeply embedded in one another. Digital technology has contributed tremendously to this ongoing transformation of popular music from an “either/or” proposition to a “both/and” hybridization that makes it increasingly difficult for listeners to distinguish between human and machine-made musical utte- rances. Put differently, one might say that digital technology has helped to humanize the machine and encouraged humans to imitate (and merge with) the machine. As a consequence, the expressions of humans and machines are today, at least in some genres, so deeply mingled that it is impossible to say where one ends and the other begins, making it very difficult at times to distinguish between human and machine.Distribution and new modes of personalized consumptionThe examples above are all about using technology in new creative ways when produ- cing music. However, consumption has also changed as a result of the shift to digital distribution technology. In the project Clouds and Concerts: Mediation and Mobility in Contemporary Music Culture (funded by the Research Council of Norway, grant 205265),
one of our aims was to study new modes of reception of music as consequences of the new modes of distribution made possible by digital technology. For the following discussion, I will in particular rely on the study of heavy users of streaming services conducted by Anja Nylund Hagen (2015b), which delves into some important aspects of the new lifeworld of music consumption that streaming brings about.Hagen’s work is a combined interview and diary study of twelve dedicated users (five men, seven women) of Spotify and WiMP Music, ranging from seventeen to sixty years old. They are high school students, higher education students and professionals in the workforce. Despite the relatively small number of informants, Hagen’s material is vast, which testifies to the thoroughness and depth of her approach. Instead of monitoring many users, that is, she decided to follow a few very closely, which encompassed access to their Facebook and last.fm accounts. Taken together, her material provided a unique perspective on media usage (an overview of the data is given in Hagen, 2015b, 58).What, then, characterizes streaming as an environment for music consumption? Hagen (2015b: 13–20) focuses on three core qualities of the streaming environment and discusses the ways in which they shape the user experience. These are:• The intangibility of the medium in which the music is made available. The loss of music’s materiality we already know from music flourishing as files online. But the intangibility of music-streaming services gives rise to an increased ephemerality and fluidity of user experience, even as it implies a new economy that make users into renters of access rather than owners of physical products. At the same time, the intangibility of the service offers the flexibility of use on various media devices. This implies user decisions regarding how to maintain music in the service, as music must be organized, stored, absorbed, and retai- ned within the changing frame of an online interface.• The abundance of the music in the services—over thirty million tracks raise issues related to how online information has been described as both a paradox and paradise of choice for users, in terms of, for example, exploration, naviga- tion, memory, and choice. Given this abundance, which practices are triggered, for what purposes, with what features, and to what effect? Implications include service orientation and music navigation—that is, how users explore, manage, navigate, remember, and retrieve music in the service.
• The social network capacity generally integrated into the platform. Music- streaming services are Internet applications and embed social networks within themselves, enabling users to announce themselves via sharing their music and listening habits with others. They also enable users to follow each other and exchange information about what people are listening to. How users deal with the social features of streaming and negotiate music as personal and social are key aspects of the new distribution platforms—surprisingly, as well, most liste- ners prefer to keep their music, and their musical tastes, to themselves (Hagen & Lüders, 2016).Hagen focuses in particular on how music listening happens everywhere and all the time in the dedicated streaming user’s everyday life, thereby strengthening music’s position there (Hagen, 2015a). Music defines or at least enhances everyday tasks and practices, routines, and responsibilities, and music streaming is part of the user’s daily ups and downs. It spans relaxing and exercising, falling asleep and waking up, being alone and being together, as is evident in the many user-generated playlists that relate to everyday activities (see table 1).Moreover, the given streaming service, via the smartphone, attaches itself to the liste- ner, often literally, which makes the practice of using music as an accompaniment to daily life more flexible than ever.moods (chilling, depressed, happy, stressed, etc.)functionality (homework, exercise, falling asleep, background)specific purposes (commuting, dinner date, party)self and others (soundtrackofmylife, brother, me-time, be tough, girls’ night, period in life)daily life rhythms (wakeup, shower, after lunch, commuting, bedtime)events and external contexts (weather, seasons, holidays, Bowie’s death, festivals, TV shows)listening modes: background/focused, shuffle/album, discoverystreaming specific contexts (“the water list”)traditional categories (artist, album, label etc.)Table 1. Personal playlists: categories (based on Hagen, 2015a)
ProsumptionHagen’s study concludes that the creative use of new distribution platforms is a means of personalized consumption, and the distance from this alignment to so-called pro- sumption practices is short. One artist who has explored the contemporary blurring of production and consumption is Imogen Heap. In March 2011, Heap started work on a new record based on fan collaboration that would result in one song every three months that was based on her fans’ various contributions. For the first song, titled “Lifeline,” people sent her nearly nine hundred “sound seeds,” such as recordings of a dishwasher door shutting, a bicycle spinning, or a match burning. Heap also sought words for a word cloud that could inspire the song’s lyrics, as well as animation/film projects for its video. The song was released on March 25, 2011, and Heap gave credit to all of the fans whose sound snippets had been included on it. “Lifeline” and other songs ultimately formed the album titled Sparks, which was completed in August 2014.An important aspect of Sparks, as well, was that it could be downloaded for free. Also her more recent song project “Tiny Human” is free. The download consists of a Dropbox folder containing an ordinary mix of the song, an instrumental version, selected tracks from the multi-track recording of the song, and related visual material, credits and a video (see figure 1). In an accompanying text on her website (Heap, 2015), Heap invited developers and services to upload the song to their platforms, provided that they created an Imogen Heap artist profile as part of this process. Instead of contributing directly to the project, fans could also donate to Heap’s Mycelia charity foundation (see figure 2).
Figure 1. Screenshot with overview of Tiny Human dropbox folder. Retrieved from http://imogenheap.com/home.php?article=2430.Figure 2. Screenshot with instructions for fans and industry. Retrieved from http://imogenheap.com/home.php?article=2430.
Imogen Heap’s music-making activities are examples of a new mode of interaction between artist and fans in which the latter are no longer purely consumers of content, since they also contribute aesthetically to its production. An even more radical form of prosumption is to be heard in the creative use of digitally based production techniques used by fans and amateurs/semi-professionals when modifying existing recordings or material from the Internet. One example is the musical mash-up, which relies on the possibility of warping samples using the DAW. A mash-up consists of two recog- nizable recordings that have been synchronized (warped) without significant edits. A prominent example is the so-called Grey Album, where Danger Mouse mashed together songs from the White Album of the Beatles with Jay-Z’s Black Album. In their analysis of this album, Brøvig-Hanssen & Harkins (2012) argue that mash-ups are characterized by two underlying principles, namely the contextual incongruity of the recognizable samples and the musical congruity of the mashed tracks. The con- textual incongruity often creates a humorous effect, as well, and one example of this experiential doubling of the music as simultaneously congruent and incongruent is “Psychosocial Baby” (2011), in which Isosine blends Slipknot’s “Psychosocial” with Justin Bieber’s “Baby”. The congruence resides in the way in which the track sounds like a virtual band performing together, whereas the incongruence resides in the track’s parodic subversion of socially established conventions. As Brøvig-Hanssen points out, this produces richness in meaning as well as several paradoxical effects (Brøvig-Hanssen, 2016).Other creative uses of new digital production tools are cut-and-paste and the afore- mentioned Auto-Tune. One prominent example of the former is a humorous edit of Barack Obama’s State of the Union speech from 2010 that was uploaded to YouTube by the pseudonym Walrus in January 2011 (available at https://www.youtube.com/ watch?v=WVmq5A4m1fU). People also make music out of public events, debates and news programs using digital pitch-correction tools such as Auto-Tune or Melodyne, producing, among other things, a series called “songify the news.” U.S. presidential candidate Donald Trump, perhaps unsurprisingly, has been subjected to songifica- tion several times (see, for example, https://www.youtube.com/watch?v=lCEQoA- 0qOic&list=PL736C3116AD309B58. Accessed 12 January 2018). Such “songify the news” tracks are clearly satirical and represent iterations of what Henry Louis Gates Jr., in theorizing African American oral verbal traditions (1988), calls signifying. They bundle repetition and revision in the same maneuver, whereby the revision then subverts the meaning of the initial utterance.
Do these practices result in music? Perhaps we might stick with musicking (Small, 1998), thanks to the prominence of their process-oriented creative approach. In any case, we would do well to note the endless creativity that is made possible by digital technology and digital media, and the impact of these new opportunities upon the ongoing blurring of music production and music consumption, both culturally and economically.Conclusion: An extension of the human?As I have discussed here, various consequences of the perceived conflict between sounds generated by a musician and sounds generated by technology have under- pinned the history of music in the twentieth century and beyond. At the same time, it remains a simple fact that playing and making music have always been embedded in technology. The opposition of human and machine in the area of music making thus comes forward as somewhat ideological: in practice, playing a traditional instrument also means being deeply involved in its technology (see, for example, Kvifte, 1989), or, in the words of Nick Prior: “It is not just that technology impacts upon music, influ- ences music, shapes music, because this form of weak technological determinism still implies two separate domains. Music is always already suffused with technology, it is embedded within technological forms and forces; it is in and of technology” (Prior, 2009: 95).Relating this point to a more general epistemological discourse, we could say that new technology creates new understanding, and that we have always learned to know the world through the tools and technologies that we use to interact with our surroun- dings. As Heidegger points out in his essay “The Question Concerning Technology” (1977), there is no alternative route to the knowledge we acquire through technology. Moreover, the insights that we derive from technology cannot be separated from the technology itself; through technology we achieve knowledge of the world in a way and to an extent that would be otherwise unavailable to us. In the words of Heidegger: “[Techne] reveals whatever does not bring itself forth and does not yet lie here before us, whatever can look and turn out now one way and now another” (Heidegger, 1977: 8). The idea that human and technology are two different things is thus, according to Heidegger, beside the point—instead, the machine should be seen as an extension of the human.
Digital technology has re-actualized this debate in music making. The creative use of new digital technology has clearly changed how music is produced, distributed, and consumed, but using technology in unforeseen ways is an old practice and should perhaps rather be understood as part of the continuous development of technology’s ever-present role as an aid to and extension of human expression and behavior. In this sense, the expressions and practices presented in this talk are yet further exam- ples of the ways in which technology has always produced new forms of knowledge, expression and behavior, thereby expanding the scope of the human imagination.ReferencesBjerke, K. Y. (2010). Timbral relationships and microrhythmic tension: Shaping the groove experience through sound. In A. Danielsen (Ed.) Musical Rhythm in the Age of Digital Reproduction, pp. 85–101. Farnham, Surrey: Ashgate.Brøvig-Hanssen, R. (2013a). Music in Bits and Bits of Music: Signatures of Digital Mediation in Popular Music Recordings. PhD diss., University of Oslo.Brøvig-Hanssen, R. & Harkins, P. (2012). Contextual incongruity and musical congruity: the aesthetics and humour of mash-ups. Popular Music, 31(01), 87–104.Brøvig-Hanssen, R. (2016). Justin Bieber Featuring Slipknot: Consumption as Mode of Production. In S. Whiteley & S. Rambarran (Eds.). The Oxford Handbook of Music and Virtuality. Oxford: Oxford University Press. doi:10.1093/ oxfordhb/9780199321285.013.19Brøvig-Hanssen, R. & Danielsen, A. (2016). Digital Signatures: The Impact of Digitization on Popular Music Sound. Cambridge, Mass.: MIT Press.Carlsen, K. & Witek, M. A. G. (2010). Simultaneous Rhythmic Events with Different Schematic Affiliations: Microtiming and Dynamic Attending in Two Contemporary R&B Grooves. In A. Danielsen (Ed.) Musical Rhythm in the Age of Digital Reproduction, pp. 51–68. Farnham, Surrey: Ashgate.Danielsen, A. (2010). Here, There and Everywhere: Three Accounts of Pulse in D’Angelo’s “Left and Right.” In A. Danielsen (Ed.) Musical Rhythm in the Age of Digital Reproduction, pp. 19–36. Farnham, Surrey: Ashgate.Gates Jr, H. L. (1988). The signifying monkey: A theory ofAfro-American literary criticism. New York: Oxford UP.Heap, I. (2015). The new music industry, Mycelia and Tiny human release.Retrieved from http://imogenheap.com/home.php?article=2430
Hagen, A. N. (2015a). The Playlist Experience: Personal Playlists in Music Streaming Services. Popular Music and Society, 38(5), 625–645.Hagen, A. N. (2015b). Using Music Streaming Services: Practices, Experiences and the Lifeworld of Musicking. PhD dissertation. University of Oslo.Hagen, A. N. & Lüders, M. (2016). Social streaming? Navigating music as personal and social. Convergence. The International Journal of Research Into New Media Technologies. doi: 10.1177/1354856516673298Harkins, P. (2010). Microsampling: From Akufen’s Microhouse to Todd Edwards and the Sound of UK Garage. In A. Danielsen (Ed.) Musical Rhythm in the Age of Digital Reproduction, pp. 177–94. Farnham, Surrey: Ashgate.Heidegger, M. (1977). The Question Concerning Technology and Other Essays. Vol. CN419. Harper Colophon Books. New York: Harper & Row.Jameson, F. (1984). Postmodernism, or the Cultural Logic of Late Capitalism. New Left Review 146, 53–92.Kvifte, T. (1989). Instruments and the Electronic Age: Toward a Terminology for a Unified Description of Playing Technique. Oslo: Solum.Prior, N. (2009). Software Sequencers and Cyborg Singers: Popular Music in the Digital Hypermodern. New Formations 66(1), 81–99.Small, C. (1998). Musicking: The Meanings of Performing and Listening. Hanover, NH: Wesleyan University Press.ProfessorAnne DanielsenInstitutt for musikkvitenskap, Universitetet i Oslo Postboks 1017 Blindern, 0315 OsloNorge anne.danielsen@imv.uio.no